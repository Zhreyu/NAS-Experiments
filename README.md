# NAS-Experiments

This repository contains code for experimenting with Neural Architecture Search (NAS) techniques. 



    * Implements a basic NAS search algorithm exploring different hyperparameters (e.g., number of neurons) for a simple neural network.
    * Demonstrates a basic approach to evaluating and selecting the best architecture based on performance.

    * Integrates with the Neural Network Intelligence (NNI) framework for hyperparameter tuning. 
    * Defines the neural network architecture and training process using NNI's parameter space definition. 
    * Allows for efficient exploration of the hyperparameter space and automated selection of the best architecture.
    * A more specific example of NAS applied to the MNIST dataset.
    * Utilizes NNI for hyperparameter tuning of a simple feedforward neural network on MNIST.

**Project Goals:**

* Explore basic concepts of Neural Architecture Search.
* Experiment with different NAS approaches (basic grid search, NNI-based search).
* Gain practical experience with hyperparameter tuning frameworks like NNI(Neural Network Intelligence).
* Develop a basic understanding of how to evaluate and select the best neural network architecture for a given task.

Date Updated: 10/01/2024